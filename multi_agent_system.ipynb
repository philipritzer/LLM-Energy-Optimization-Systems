{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import functools\n",
    "import operator\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Annotated\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "import requests\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "import chat_apps.auth_keys as auth_keys\n",
    "import chat_apps.myconfig as myconfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = auth_keys.openai_api_key\n",
    "os.environ[\"OPENWEATHERMAP_API_KEY\"] = auth_keys.openweather_api_key\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = auth_keys.langchain_api_key\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"multi_agent\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# State",
   "id": "353b3dae07d4d0ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str"
   ],
   "id": "82f5f5dc1faa6aff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = ChatOpenAI(model='gpt-4o', temperature=0)",
   "id": "d0e2bc7011df9c90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tools",
   "id": "10ef4669811b9c4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "python_repl_tool = PythonREPLTool()",
   "id": "d17ee91f8541f294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@tool(\"live_data\")\n",
    "def get_live_data():\n",
    "    \"\"\"Retrieves live data of the solar system\"\"\"\n",
    "    base_url = myconfig.url_to_raspberry_rest_api\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url)\n",
    "        return response.json()\n",
    "    except:\n",
    "        return \"There was an error retrieving the data.\"\n",
    "\n",
    "\n",
    "@tool(\"summed_historic_data\")\n",
    "def get_summed_historic_data():\n",
    "    \"\"\"Retrieves the summed up historic solar data\"\"\"\n",
    "    base_url = myconfig.url_summed_up_data\n",
    "    response = requests.get(base_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        output_string = \"Energy Historic Data last three days: \\n\"\n",
    "        for idx, entry in enumerate(data):\n",
    "            date = entry['date']\n",
    "            consumption_positive = entry['consumption_positive']\n",
    "            grid_negative = entry['grid_negative']\n",
    "            grid_positive = entry['grid_positive']\n",
    "            production_positive = entry['production_positive']\n",
    "\n",
    "            if idx == len(data) - 1:\n",
    "                date_description = datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%d.%m.%Y\") + \" (today)\"\n",
    "            else:\n",
    "                date_description = datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%d.%m.%Y\")\n",
    "\n",
    "            entry_string = f\"\"\"\n",
    "    Date: {date_description}\n",
    "    - Consumption Positive: {consumption_positive}\n",
    "    - Grid Negative: {grid_negative}\n",
    "    - Grid Positive: {grid_positive}\n",
    "    - Production Positive: {production_positive}\n",
    "        \"\"\"\n",
    "            output_string += entry_string\n",
    "        output_string += \"\\n \\nGrid Positive is how much was drawn from the grid. \\nGrid negative is how much was fed into the grid.\"\n",
    "        return output_string\n",
    "    else:\n",
    "        return \"There was an error retrieving the data.\"\n",
    "\n",
    "\n",
    "@tool(\"weather_forecaster\")\n",
    "def get_weather_forecast():\n",
    "    \"\"\"Retrieves the current weather and the forecast for the next 3 days.\"\"\"\n",
    "    base_url = \"https://api.openweathermap.org/data/2.5/forecast/daily\"\n",
    "    params = {\n",
    "        'lat': '49.300652',\n",
    "        'lon': '10.571460',\n",
    "        'appid': auth_keys.openweather_api_key,\n",
    "        'units': 'metric'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    print(response.url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        export_data = {}\n",
    "        for i in range(4):\n",
    "            export_data[i] = {\n",
    "                \"date\": data[\"list\"][i][\"dt\"],\n",
    "                \"temp\": data[\"list\"][i][\"temp\"][\"day\"],\n",
    "                \"weather\": data[\"list\"][i][\"weather\"][0][\"main\"],\n",
    "                \"clouds\": data[\"list\"][i][\"clouds\"],\n",
    "            }\n",
    "\n",
    "        output_string = f\"\"\"\n",
    "Weather Forecast\n",
    "Today's Forecast:\n",
    "Date: {datetime.utcfromtimestamp(data[\"list\"][0][\"dt\"]).strftime('%Y-%m-%d')}\n",
    "Temperature: {export_data[0][\"temp\"]} 째C\n",
    "Weather: {export_data[0][\"weather\"]}\n",
    "Cloud Coverage: {export_data[0][\"clouds\"]}%\n",
    "\n",
    "Next 3 Days:\n",
    "Day 1 - {datetime.utcfromtimestamp(data[\"list\"][1][\"dt\"]).strftime('%Y-%m-%d')}\n",
    "Temperature: {export_data[1][\"temp\"]} 째C\n",
    "Weather: {export_data[1][\"weather\"]}\n",
    "Cloud Coverage: {export_data[1][\"clouds\"]}%\n",
    "\n",
    "Day 2 - {datetime.utcfromtimestamp(data[\"list\"][2][\"dt\"]).strftime('%Y-%m-%d')}\n",
    "Temperature: {export_data[2][\"temp\"]} 째C\n",
    "Weather: {export_data[2][\"weather\"]}\n",
    "Cloud Coverage: {export_data[2][\"clouds\"]}%\n",
    "\n",
    "Day 3 - {datetime.utcfromtimestamp(data[\"list\"][3][\"dt\"]).strftime('%Y-%m-%d')}\n",
    "Temperature: {export_data[3][\"temp\"]} 째C\n",
    "Weather: {export_data[3][\"weather\"]}\n",
    "Cloud Coverage: {export_data[3][\"clouds\"]}%\n",
    "\"\"\"\n",
    "        return output_string\n",
    "    else:\n",
    "        return \"There was an error retrieving the data.\"\n"
   ],
   "id": "a98d211ee0012a7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper Utils",
   "id": "d90c9b763eb08ca8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "    )\n",
    "    return executor"
   ],
   "id": "fbb4f96d6a80a4d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def agent_node(state: AgentState, agent: AgentExecutor, name: str):\n",
    "    result = agent.invoke(state)\n",
    "    if name == \"Energy optimizer\":\n",
    "        return {\"messages\": [HumanMessage(content=result[\"output\"])]}\n",
    "    else:\n",
    "        return {\"messages\": [HumanMessage(content=name + ' says: \\n' + result[\"output\"])]}\n",
    "\n",
    "\n",
    "def weather_state_update(state: AgentState, agent: AgentExecutor, name: str):\n",
    "    print(\"weather_state_update called\")\n",
    "    result = agent.invoke(state)\n",
    "    \n",
    "    updated_content = (\n",
    "        f\"{state.get('messages')[0].content}\\n\"\n",
    "        \"____additional information____\\n\\n\"\n",
    "        f\"{result['output']}\\n\"\n",
    "        \"The data has successfully been retrieved.\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=updated_content)],\n",
    "        \"next\": \"supervisor\",\n",
    "        \"intermediate_steps\": [(name, str(result))]\n",
    "    }"
   ],
   "id": "db98fde260c7d2ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "analyzers = [\"Weather Retriever\", \"Coder\"]\n",
    "nodes = analyzers + [\"Energy optimizer\"]\n",
    "system_prompt = (\n",
    "    f\"\"\"You are the Supervisor. Your task is to manage the conversation between the nodes and decide which node should be called next.\n",
    "\n",
    "Follow these guidelines:\n",
    "\n",
    "If the user asks about the current weather or a weather forecast, route the request to the Weather Retriever.\n",
    "If the user requests data on energy production, consumption, or grid interaction of the solar panel system, or any visualization route the request to the Coder.\n",
    "If the user needs specific optimization suggestions regarding energy usage, route the request to the Energy optimizer.\n",
    "If the user's request does not clearly fit into any of the above categories, decide based on the context which node can provide the most appropriate response. If you can't decide chose the Energy optimizer.\n",
    "If the question has nothing to do with any topic or no additional data is required select Energy optimizer\n",
    "If there is a question about any energy usage intense task check the weather to plan that task\n",
    "If additional data is required select one of: {analyzers}\n",
    "\n",
    "You can chose between {nodes}\n",
    "     \"\"\"\n",
    ")\n",
    "options = nodes\n",
    "\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \"If the question has nothing to do with any topic select Energy optimizer \"\n",
    "            \"If no additional data is required to answer the question select Energy optimizer \"\n",
    "            \"If additional data is required select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(nodes))\n",
    "\n",
    "supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    ")"
   ],
   "id": "912a49ae5696eded",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weather_retriever = create_agent(llm, [get_weather_forecast],\n",
    "                                 \"\"\"You are the Weather Retriever. Your task is to provide the current weather and the weather forecast for a predefined location.\"\"\")\n",
    "weather_retriever_node = functools.partial(weather_state_update, agent=weather_retriever, name=\"Weather Retriever\")\n",
    "\n",
    "code_agent = create_agent(llm, [python_repl_tool, get_summed_historic_data, get_live_data],\n",
    "                          \"You may generate safe Python code to analyze data and generate charts using matplotlib. If your task ist to plot solar data you can request time series data with python from the endpoint <insert url here>, it returns the solar data in csv format. The data covers the last three days and includes the following keys: production (in kWh), grid (in kWh), consumption (in kWh), timestamp, battery_status (in %). The timestamp is formatted as follows: YYYY-MM-DDTHH:MM:SS. \\n. Don't use double quotes in the code \\n\"\n",
    "                          \"  Answer only with your results and never ask follow up questions.\")\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "analyze_agent = create_agent(llm, [],\n",
    "                             \"\"\"You are an energy optimizer. You analyze solar and weather data to provide insights on energy usage and optimization. This includes identifying non-optimal energy usage periods, suggesting optimal times for high energy consumption based on solar production and weather forecast, and offering general energy-saving recommendations. Energy from the solar panel is free, so always prioritize power coming from the solar panel. Recommend times where the sun is shining for energy-intensive tasks to utilize the free energy from the solar panel. When analyzing the data, consider the following hierarchy of factors: \n",
    "                             Solar Production: Prioritize recommendations based on periods with the highest expected solar energy production.\n",
    "                             Weather Conditions: Consider weather conditions such as cloud cover and precipitation that affect solar production.\n",
    "                             Temperature: Suggest energy-intensive tasks during periods with favorable temperatures, if solar production is insufficient.\n",
    "                             When you receive information from the coder, repeat it and analyze it according to the above factors. Please give tips on how to analyze a visualization if the coder responded with a visualization. Don't interact with the coder or weather retriever, just pass the information as it would be yours.\"\"\")\n",
    "analyze_node = functools.partial(agent_node, agent=analyze_agent, name=\"Energy optimizer\")"
   ],
   "id": "1505149516e40f96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"Weather Retriever\", weather_retriever_node)\n",
    "graph.add_node(\"Coder\", code_node)\n",
    "graph.add_node(\"Energy optimizer\", analyze_node)\n",
    "graph.add_node(\"supervisor\", supervisor_chain)"
   ],
   "id": "8def8558b0e09fdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for analyzer in analyzers:\n",
    "    graph.add_edge(analyzer, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in analyzers}\n",
    "conditional_map[\"Energy optimizer\"] = \"Energy optimizer\"\n",
    "graph.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "graph.add_edge(\"Energy optimizer\", END)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")"
   ],
   "id": "40c0a43592d826bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph = graph.compile()",
   "id": "f039ab795d91c471",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ],
   "id": "2a9032a18a7705b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\"recursion_limit\": 10}\n",
    "output = \"\"\n",
    "for s in graph.stream(\n",
    "        {\n",
    "            \"messages\": [HumanMessage(\n",
    "                \"Give me a summary of my solar data.\")]\n",
    "        }, config=config\n",
    "):\n",
    "    print(s)\n",
    "    output = s"
   ],
   "id": "8844f462f56fce8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(output['Energy optimizer']['messages'][0].content)",
   "id": "1ac2a737e6255411",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
